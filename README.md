# Major_Project
This project aimed to survey the realm of heart-stroke discovery and the potential of utilizing Quantum Computing to upgrade this critical facet of healthcare. Traditional designs for detecting heart strokes frequently encounter challenges related to their veracity and computational complexity. To overcome these restraints, Our system influences the unique possessions of quantum computing, particularly the phenomenon of destructive interference, to guarantee that clustering everything works correctly and is doable for requests in real-world questions. By joining the K-means clustering accompanying the quantum principles, our approach aims to provide a more accurate and adept discovery of heart stroke.
In our study, we conducted inclusive experiments utilizing various datasets of patients with accompanying heart stroke to judge the performance. The findings show that our method outperforms established patterns and former quantum methods, exhibiting superior veracity and adeptness in heart-stroke discovery. 
The ability to correctly and efficiently discover heart stroke using quantum-driven approaches can bring about proper mediation, upgraded patient outcomes, and diminished healthcare costs, which in a proper sequence will lead to a lower number of afterlife events from heart stroke. Moreover, the verdicts shed light on the potential of quantum computing to advance accuracy cure, and personalized healthcare.
## Dataset Description
The Stroke Prediction Dataset offers a rich collection of records aimed at understanding and predicting the occurrence of strokes. This dataset comprises a range of relevant attributes that provide insights into various aspects related to strokes. The dataset consists of 12 features, including the target attribute that signifies whether a patient has experienced a stroke (Target = "1") or not (Target = "0").
The dataset encompasses diverse information about each patient, including their age, sex, hypertension status, presence of heart disease, whether they are married or not, the type of work they are engaged in, their residence type, average glucose level, body mass index (BMI), smoking status, and the availability of relevant medical history. Each of these features contributes to the comprehensive nature of the dataset, enabling researchers and data scientists to explore the potential risk factors and patterns associated with strokes.
To ensure the dataset's compatibility with machine learning algorithms, preprocessing steps are required, including data cleansing, handling missing values, and feature engineering techniques such as encoding categorical variables. By applying these preprocessing techniques, researchers can unlock the dataset's potential and utilize machine learning algorithms to develop predictive models that can aid in stroke prevention and treatment strategies. The next sections describe the various preprocessing steps, such as Dimensionality reduction, outlier rejection, feature scaling, etc. used during the course of our study. 
